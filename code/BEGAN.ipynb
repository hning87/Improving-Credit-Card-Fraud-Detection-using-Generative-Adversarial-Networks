{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "D:\\Program Files\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "D:\\Program Files\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "D:\\Program Files\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n",
      "D:\\Program Files\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Program Files\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Program Files\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Program Files\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Program Files\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Program Files\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\Program Files\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Program Files\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Program Files\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Program Files\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Program Files\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Program Files\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\Program Files\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "D:\\Program Files\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "import os\n",
    "from keras.layers import Input, Embedding, multiply, BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.core import Reshape, Dense, Dropout, Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras import initializers\n",
    "from keras import applications\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.initializers import glorot_normal\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import generic_utils\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Program Files\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv('creditcard.csv')\n",
    "df_raw['Amount'] = np.log10(df_raw['Amount'].values + 1)\n",
    "df_raw['Time'] = (df_raw['Time'].values/3600)\n",
    "\n",
    "\n",
    "target = 'Class'\n",
    "\n",
    "# Divide the training data into training (80%) and test (20%)\n",
    "df_train, df_test = train_test_split(df_raw, train_size=0.8, random_state=42, stratify=df_raw[target])\n",
    "\n",
    "# Reset the index\n",
    "df_train, df_test = df_train.reset_index(drop=True), df_test.reset_index(drop=True)\n",
    "\n",
    "x_train_fraud = df_train[df_train['Class'] == 1].drop(target, axis=1)\n",
    "\n",
    "x_train = df_train.drop(target, axis=1)\n",
    "y_train = df_train[target]\n",
    "x_test = df_test.drop(target, axis=1)\n",
    "y_test = df_test[target]\n",
    "\n",
    "\n",
    "# %% --------------------------------------- Set Seeds -----------------------------------------------------------------\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "weight_init = glorot_normal(seed=SEED)\n",
    "\n",
    "# %% ---------------------------------- Hyperparameters ----------------------------------------------------------------\n",
    "latent_dim = 32\n",
    "data_dim = len(x_train.columns)\n",
    "n_classes = len(np.unique(y_train))\n",
    "optimizer = Adam(lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Encoder\n",
    "def encoder():\n",
    "    data = Input(shape=(data_dim,))\n",
    "    \n",
    "    x = Dense(256, kernel_initializer=weight_init)(data)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = Dense(128, kernel_initializer=weight_init)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = Dense(64, kernel_initializer=weight_init)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    encodered = Dense(latent_dim)(x)\n",
    "\n",
    "    model = Model(inputs=data, outputs=encodered)\n",
    "    return model\n",
    "\n",
    "def decoder():\n",
    "    noise = Input(shape=(latent_dim,))\n",
    "\n",
    "    x = Dense(64, kernel_initializer=weight_init)(noise)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = Dense(128, kernel_initializer=weight_init)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = Dense(256, kernel_initializer=weight_init)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    generated = Dense(data_dim, kernel_initializer=weight_init)(x)\n",
    "\n",
    "    generator = Model(inputs=noise, outputs=generated)\n",
    "    return generator\n",
    "\n",
    "def generator(decoder):\n",
    "\n",
    "    noise = Input(shape=(latent_dim,))\n",
    "\n",
    "    generated_feature = decoder(noise)\n",
    "    model = Model(inputs=noise, outputs=generated_feature)\n",
    "\n",
    "    return model\n",
    "\n",
    "def discriminator(encoder, decoder):\n",
    "\n",
    "    data = Input(shape=(data_dim,))\n",
    "    \n",
    "    x = encoder(data)\n",
    "    out = decoder(x)\n",
    "\n",
    "    model = Model(inputs=data, outputs=out)\n",
    "    model.compile(optimizer=optimizer, loss=l1Loss)\n",
    "    return model\n",
    "\n",
    "def l1Loss(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_true - y_pred))\n",
    "\n",
    "def train_G(generator, discriminator):\n",
    "    # Freeze the discriminator when training generator\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    model.compile(optimizer=optimizer, loss=l1Loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BEGAN:\n",
    "    def __init__(self, g_model, d_model, kLambda = 0.000001, k=0.06):\n",
    "        self.z = latent_dim\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        self.generator = g_model\n",
    "        self.discriminator = d_model\n",
    "        self.kLambda = kLambda\n",
    "        self.k = k\n",
    "        \n",
    "        self.train_G = train_G(self.generator, self.discriminator)\n",
    "        self.loss_D, self.loss_G = [], []\n",
    "        \n",
    "    def train(self, data, batch_size, steps_per_epoch=100, gamma=0.5):\n",
    "\n",
    "        for epoch in range(steps_per_epoch):\n",
    "            # Select a random batch of transactions data\n",
    "            idx = np.random.randint(0, data.shape[0], batch_size)\n",
    "            real_data = data[idx]\n",
    "\n",
    "            # generate a batch of new data\n",
    "            noise_D = np.random.normal(0, 1, size=(batch_size, latent_dim))\n",
    "            fake_data_D = self.generator.predict(noise_D)\n",
    "\n",
    "            # Train D\n",
    "            d_loss_real = self.discriminator.train_on_batch(real_data, real_data)\n",
    "            \n",
    "            weights = -self.k * np.ones(batch_size)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(fake_data_D, fake_data_D, weights)\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            self.loss_D.append(d_loss)\n",
    "\n",
    "            # Train G\n",
    "            noise_G = np.random.normal(0, 1, size=(batch_size, latent_dim))\n",
    "            fake_data_G = self.generator.predict(noise_G)\n",
    "            loss_g = self.train_G.train_on_batch(noise_G, fake_data_G)\n",
    "            self.loss_G.append(loss_g)\n",
    "\n",
    "            #Update k\n",
    "            self.k = self.k + self.kLambda * (gamma * d_loss_real - loss_g)\n",
    "            self.k = min(max(self.k, 1e-05), 1)\n",
    "\n",
    "            #Report Results\n",
    "            m_global = d_loss + np.abs(gamma*d_loss_real - loss_g)\n",
    "                \n",
    "            if (epoch + 1) * 10 % steps_per_epoch == 0:\n",
    "                print('Steps (%d / %d): [loss_D: %f] [Loss_G: %f] [M_global: %f]' %\n",
    "                  (epoch+1, steps_per_epoch, 100*self.loss_D[-1], self.loss_G[-1], m_global))\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "def boxplot_compare(df1, df2,title):\n",
    "  fig, ax = plt.subplots(figsize=(16,10))\n",
    "  bp1 = df1.boxplot(color='green', showfliers=False)\n",
    "  bp2 = df2.boxplot(color='hotpink', showfliers=False)\n",
    "\n",
    "  patch1 = mpatches.Patch(color='green', label='Original')\n",
    "  patch2 = mpatches.Patch(color='hotpink', label='BEGAN')\n",
    "  plt.legend(handles=[patch1, patch2], prop={'size': 16})\n",
    "  ax.set_title(title)\n",
    "  plt.xticks(rotation=90)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(generator, n_data):\n",
    "    noise = np.random.normal(0, 1, size=(n_data, latent_dim))\n",
    "    gen = generator.predict(noise)\n",
    "    x_train_gen = np.concatenate((x_train, gen))\n",
    "    y_gen = np.array(gen.shape[0] * [1])\n",
    "    y_train_gen = np.concatenate((y_train, y_gen))\n",
    "    return gen, x_train_gen, y_train_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #  1 --------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "D:\\Program Files\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "D:\\Program Files\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps (10 / 100): [loss_D: 258.182621] [Loss_G: 0.323131] [M_global: 3.559384]\n",
      "Steps (20 / 100): [loss_D: 178.518414] [Loss_G: 0.536941] [M_global: 2.157022]\n",
      "Steps (30 / 100): [loss_D: 136.715806] [Loss_G: 0.664502] [M_global: 1.406800]\n",
      "Steps (40 / 100): [loss_D: 108.681452] [Loss_G: 0.776678] [M_global: 1.296686]\n",
      "Steps (50 / 100): [loss_D: 100.062120] [Loss_G: 1.134572] [M_global: 1.600144]\n",
      "Steps (60 / 100): [loss_D: 115.734398] [Loss_G: 1.226584] [M_global: 1.771050]\n",
      "Steps (70 / 100): [loss_D: 81.058800] [Loss_G: 0.811663] [M_global: 1.192036]\n",
      "Steps (80 / 100): [loss_D: 78.831214] [Loss_G: 0.561605] [M_global: 0.938429]\n",
      "Steps (90 / 100): [loss_D: 74.862576] [Loss_G: 0.508255] [M_global: 0.868088]\n",
      "Steps (100 / 100): [loss_D: 66.013592] [Loss_G: 0.470927] [M_global: 0.787031]\n",
      "EPOCH #  2 --------------------------------------------------\n",
      "Steps (10 / 100): [loss_D: 61.332864] [Loss_G: 0.462651] [M_global: 0.755350]\n",
      "Steps (20 / 100): [loss_D: 62.697154] [Loss_G: 0.472021] [M_global: 0.770637]\n",
      "Steps (30 / 100): [loss_D: 69.703263] [Loss_G: 0.501326] [M_global: 0.834438]\n",
      "Steps (40 / 100): [loss_D: 65.611792] [Loss_G: 0.530528] [M_global: 0.842513]\n",
      "Steps (50 / 100): [loss_D: 66.132128] [Loss_G: 0.602554] [M_global: 0.915142]\n",
      "Steps (60 / 100): [loss_D: 57.312483] [Loss_G: 0.702095] [M_global: 0.967892]\n",
      "Steps (70 / 100): [loss_D: 59.444016] [Loss_G: 0.861312] [M_global: 1.132466]\n",
      "Steps (80 / 100): [loss_D: 56.917733] [Loss_G: 1.166560] [M_global: 1.419537]\n",
      "Steps (90 / 100): [loss_D: 50.410235] [Loss_G: 1.570673] [M_global: 1.776507]\n",
      "Steps (100 / 100): [loss_D: 41.977417] [Loss_G: 1.935294] [M_global: 2.088988]\n",
      "EPOCH #  3 --------------------------------------------------\n",
      "Steps (10 / 100): [loss_D: 42.355633] [Loss_G: 1.962427] [M_global: 2.115207]\n",
      "Steps (20 / 100): [loss_D: 46.460283] [Loss_G: 1.686764] [M_global: 1.869055]\n",
      "Steps (30 / 100): [loss_D: 54.765487] [Loss_G: 1.392317] [M_global: 1.628401]\n",
      "Steps (40 / 100): [loss_D: 56.272441] [Loss_G: 1.103891] [M_global: 1.351891]\n",
      "Steps (50 / 100): [loss_D: 43.517241] [Loss_G: 0.800098] [M_global: 0.992562]\n",
      "Steps (60 / 100): [loss_D: 50.481468] [Loss_G: 0.680159] [M_global: 0.911683]\n",
      "Steps (70 / 100): [loss_D: 53.465176] [Loss_G: 0.689322] [M_global: 0.935353]\n",
      "Steps (80 / 100): [loss_D: 48.713505] [Loss_G: 0.715663] [M_global: 0.938423]\n",
      "Steps (90 / 100): [loss_D: 47.904965] [Loss_G: 0.672644] [M_global: 0.892687]\n",
      "Steps (100 / 100): [loss_D: 51.528925] [Loss_G: 0.723167] [M_global: 0.959814]\n",
      "EPOCH #  4 --------------------------------------------------\n",
      "Steps (10 / 100): [loss_D: 50.407946] [Loss_G: 0.737463] [M_global: 0.968384]\n",
      "Steps (20 / 100): [loss_D: 51.695567] [Loss_G: 0.744853] [M_global: 0.981361]\n",
      "Steps (30 / 100): [loss_D: 45.513439] [Loss_G: 0.733697] [M_global: 0.938836]\n",
      "Steps (40 / 100): [loss_D: 50.597155] [Loss_G: 0.799748] [M_global: 1.028438]\n",
      "Steps (50 / 100): [loss_D: 53.068954] [Loss_G: 0.859419] [M_global: 1.099193]\n",
      "Steps (60 / 100): [loss_D: 45.223850] [Loss_G: 0.915018] [M_global: 1.113025]\n",
      "Steps (70 / 100): [loss_D: 41.453618] [Loss_G: 1.131605] [M_global: 1.306780]\n",
      "Steps (80 / 100): [loss_D: 44.604385] [Loss_G: 1.375346] [M_global: 1.554502]\n",
      "Steps (90 / 100): [loss_D: 39.749488] [Loss_G: 1.648459] [M_global: 1.798621]\n",
      "Steps (100 / 100): [loss_D: 40.360621] [Loss_G: 1.672543] [M_global: 1.829279]\n",
      "EPOCH #  5 --------------------------------------------------\n",
      "Steps (10 / 100): [loss_D: 43.342215] [Loss_G: 1.242044] [M_global: 1.422110]\n",
      "Steps (20 / 100): [loss_D: 44.995821] [Loss_G: 1.014841] [M_global: 1.210430]\n",
      "Steps (30 / 100): [loss_D: 44.258052] [Loss_G: 0.806515] [M_global: 1.003439]\n",
      "Steps (40 / 100): [loss_D: 48.576573] [Loss_G: 0.763479] [M_global: 0.984340]\n",
      "Steps (50 / 100): [loss_D: 43.407205] [Loss_G: 0.758525] [M_global: 0.953981]\n",
      "Steps (60 / 100): [loss_D: 46.151119] [Loss_G: 0.780981] [M_global: 0.988509]\n",
      "Steps (70 / 100): [loss_D: 40.188485] [Loss_G: 0.938727] [M_global: 1.114794]\n",
      "Steps (80 / 100): [loss_D: 41.926184] [Loss_G: 1.009346] [M_global: 1.188250]\n",
      "Steps (90 / 100): [loss_D: 40.212759] [Loss_G: 1.148943] [M_global: 1.317092]\n",
      "Steps (100 / 100): [loss_D: 34.448159] [Loss_G: 1.263523] [M_global: 1.397509]\n",
      "EPOCH #  6 --------------------------------------------------\n",
      "Steps (10 / 100): [loss_D: 41.180766] [Loss_G: 1.440521] [M_global: 1.604194]\n",
      "Steps (20 / 100): [loss_D: 34.651393] [Loss_G: 1.562498] [M_global: 1.687064]\n",
      "Steps (30 / 100): [loss_D: 32.962540] [Loss_G: 1.783514] [M_global: 1.896580]\n",
      "Steps (40 / 100): [loss_D: 34.264889] [Loss_G: 1.818754] [M_global: 1.935352]\n",
      "Steps (50 / 100): [loss_D: 36.632791] [Loss_G: 1.756172] [M_global: 1.886603]\n",
      "Steps (60 / 100): [loss_D: 36.164525] [Loss_G: 1.706339] [M_global: 1.834443]\n",
      "Steps (70 / 100): [loss_D: 34.534746] [Loss_G: 1.629578] [M_global: 1.751935]\n",
      "Steps (80 / 100): [loss_D: 33.597195] [Loss_G: 1.429079] [M_global: 1.552829]\n",
      "Steps (90 / 100): [loss_D: 33.744267] [Loss_G: 1.327986] [M_global: 1.453484]\n",
      "Steps (100 / 100): [loss_D: 38.485301] [Loss_G: 1.291650] [M_global: 1.447220]\n",
      "EPOCH #  7 --------------------------------------------------\n",
      "Steps (10 / 100): [loss_D: 36.240223] [Loss_G: 1.259668] [M_global: 1.401309]\n",
      "Steps (20 / 100): [loss_D: 35.013098] [Loss_G: 1.306988] [M_global: 1.443432]\n",
      "Steps (30 / 100): [loss_D: 37.104812] [Loss_G: 1.373158] [M_global: 1.520959]\n",
      "Steps (40 / 100): [loss_D: 26.101124] [Loss_G: 1.393048] [M_global: 1.482807]\n",
      "Steps (50 / 100): [loss_D: 35.051930] [Loss_G: 1.334778] [M_global: 1.471145]\n",
      "Steps (60 / 100): [loss_D: 38.820264] [Loss_G: 1.322702] [M_global: 1.476037]\n",
      "Steps (70 / 100): [loss_D: 33.627725] [Loss_G: 1.375713] [M_global: 1.503905]\n",
      "Steps (80 / 100): [loss_D: 32.013950] [Loss_G: 1.381975] [M_global: 1.501072]\n",
      "Steps (90 / 100): [loss_D: 31.702304] [Loss_G: 1.363822] [M_global: 1.481109]\n",
      "Steps (100 / 100): [loss_D: 35.937560] [Loss_G: 1.353794] [M_global: 1.495260]\n",
      "EPOCH #  8 --------------------------------------------------\n",
      "Steps (10 / 100): [loss_D: 35.465237] [Loss_G: 1.377613] [M_global: 1.514693]\n",
      "Steps (20 / 100): [loss_D: 33.224750] [Loss_G: 1.464516] [M_global: 1.587298]\n",
      "Steps (30 / 100): [loss_D: 28.173348] [Loss_G: 1.584969] [M_global: 1.679572]\n",
      "Steps (40 / 100): [loss_D: 27.146441] [Loss_G: 1.671540] [M_global: 1.755032]\n",
      "Steps (50 / 100): [loss_D: 27.619573] [Loss_G: 2.037033] [M_global: 2.115250]\n",
      "Steps (60 / 100): [loss_D: 24.863657] [Loss_G: 2.490999] [M_global: 2.546208]\n",
      "Steps (70 / 100): [loss_D: 20.443305] [Loss_G: 3.062500] [M_global: 3.078816]\n",
      "Steps (80 / 100): [loss_D: 16.294721] [Loss_G: 3.534038] [M_global: 3.505305]\n",
      "Steps (90 / 100): [loss_D: 20.540632] [Loss_G: 3.872666] [M_global: 3.856684]\n",
      "Steps (100 / 100): [loss_D: 16.415322] [Loss_G: 3.953529] [M_global: 3.923251]\n",
      "EPOCH #  9 --------------------------------------------------\n",
      "Steps (10 / 100): [loss_D: 24.688432] [Loss_G: 3.679054] [M_global: 3.698867]\n",
      "Steps (20 / 100): [loss_D: 20.810705] [Loss_G: 3.537293] [M_global: 3.539859]\n",
      "Steps (30 / 100): [loss_D: 19.267690] [Loss_G: 4.273152] [M_global: 4.242729]\n",
      "Steps (40 / 100): [loss_D: 10.818481] [Loss_G: 5.184894] [M_global: 5.084042]\n",
      "Steps (50 / 100): [loss_D: 9.955695] [Loss_G: 5.478495] [M_global: 5.353917]\n",
      "Steps (60 / 100): [loss_D: 16.155899] [Loss_G: 5.089341] [M_global: 5.018747]\n",
      "Steps (70 / 100): [loss_D: 19.321457] [Loss_G: 5.071218] [M_global: 5.024799]\n",
      "Steps (80 / 100): [loss_D: 14.311951] [Loss_G: 4.305503] [M_global: 4.242759]\n",
      "Steps (90 / 100): [loss_D: 18.331288] [Loss_G: 4.028523] [M_global: 4.001631]\n",
      "Steps (100 / 100): [loss_D: 23.200126] [Loss_G: 3.399579] [M_global: 3.418198]\n",
      "EPOCH #  10 --------------------------------------------------\n",
      "Steps (10 / 100): [loss_D: 23.814875] [Loss_G: 2.664754] [M_global: 2.708987]\n",
      "Steps (20 / 100): [loss_D: 29.805851] [Loss_G: 1.968509] [M_global: 2.057595]\n",
      "Steps (30 / 100): [loss_D: 32.478181] [Loss_G: 1.559033] [M_global: 1.674201]\n",
      "Steps (40 / 100): [loss_D: 31.582093] [Loss_G: 1.360076] [M_global: 1.479109]\n",
      "Steps (50 / 100): [loss_D: 34.228057] [Loss_G: 1.254011] [M_global: 1.387739]\n",
      "Steps (60 / 100): [loss_D: 36.194313] [Loss_G: 1.233578] [M_global: 1.380198]\n",
      "Steps (70 / 100): [loss_D: 30.898166] [Loss_G: 1.058602] [M_global: 1.179695]\n",
      "Steps (80 / 100): [loss_D: 30.042955] [Loss_G: 1.166616] [M_global: 1.282931]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps (90 / 100): [loss_D: 30.578968] [Loss_G: 0.982029] [M_global: 1.102883]\n",
      "Steps (100 / 100): [loss_D: 31.726423] [Loss_G: 1.021839] [M_global: 1.150622]\n",
      "EPOCH #  11 --------------------------------------------------\n",
      "Steps (10 / 100): [loss_D: 34.046403] [Loss_G: 0.999441] [M_global: 1.141670]\n",
      "Steps (20 / 100): [loss_D: 34.809467] [Loss_G: 0.923167] [M_global: 1.070271]\n",
      "Steps (30 / 100): [loss_D: 32.214037] [Loss_G: 0.861862] [M_global: 0.997802]\n",
      "Steps (40 / 100): [loss_D: 37.186813] [Loss_G: 0.883166] [M_global: 1.044136]\n",
      "Steps (50 / 100): [loss_D: 38.793612] [Loss_G: 0.875320] [M_global: 1.043612]\n",
      "Steps (60 / 100): [loss_D: 31.591678] [Loss_G: 0.801828] [M_global: 0.935803]\n",
      "Steps (70 / 100): [loss_D: 35.258472] [Loss_G: 0.793220] [M_global: 0.947578]\n",
      "Steps (80 / 100): [loss_D: 38.050091] [Loss_G: 0.727470] [M_global: 0.895528]\n",
      "Steps (90 / 100): [loss_D: 32.622015] [Loss_G: 0.732002] [M_global: 0.873656]\n",
      "Steps (100 / 100): [loss_D: 32.118493] [Loss_G: 0.706403] [M_global: 0.845527]\n",
      "EPOCH #  12 --------------------------------------------------\n",
      "Steps (10 / 100): [loss_D: 32.415175] [Loss_G: 0.719753] [M_global: 0.861228]\n",
      "Steps (20 / 100): [loss_D: 30.422810] [Loss_G: 0.663402] [M_global: 0.793489]\n",
      "Steps (30 / 100): [loss_D: 30.596361] [Loss_G: 0.708727] [M_global: 0.840746]\n",
      "Steps (40 / 100): [loss_D: 35.417053] [Loss_G: 0.717281] [M_global: 0.873206]\n",
      "Steps (50 / 100): [loss_D: 29.665568] [Loss_G: 0.764762] [M_global: 0.892795]\n",
      "Steps (60 / 100): [loss_D: 33.378670] [Loss_G: 0.691446] [M_global: 0.838925]\n",
      "Steps (70 / 100): [loss_D: 32.128844] [Loss_G: 0.654554] [M_global: 0.795060]\n",
      "Steps (80 / 100): [loss_D: 37.556753] [Loss_G: 0.634280] [M_global: 0.803620]\n",
      "Steps (90 / 100): [loss_D: 33.902723] [Loss_G: 0.610464] [M_global: 0.761118]\n",
      "Steps (100 / 100): [loss_D: 28.347099] [Loss_G: 0.566804] [M_global: 0.691833]\n",
      "EPOCH #  13 --------------------------------------------------\n",
      "Steps (10 / 100): [loss_D: 28.179821] [Loss_G: 0.525189] [M_global: 0.649072]\n",
      "Steps (20 / 100): [loss_D: 33.761317] [Loss_G: 0.532788] [M_global: 0.686861]\n",
      "Steps (30 / 100): [loss_D: 29.214704] [Loss_G: 0.496644] [M_global: 0.628126]\n",
      "Steps (40 / 100): [loss_D: 34.725031] [Loss_G: 0.505747] [M_global: 0.664931]\n",
      "Steps (50 / 100): [loss_D: 32.970783] [Loss_G: 0.491811] [M_global: 0.642007]\n",
      "Steps (60 / 100): [loss_D: 31.671539] [Loss_G: 0.542258] [M_global: 0.685738]\n",
      "Steps (70 / 100): [loss_D: 32.283992] [Loss_G: 0.593508] [M_global: 0.739198]\n",
      "Steps (80 / 100): [loss_D: 29.472911] [Loss_G: 0.673129] [M_global: 0.799799]\n",
      "Steps (90 / 100): [loss_D: 30.994058] [Loss_G: 0.820896] [M_global: 0.950685]\n",
      "Steps (100 / 100): [loss_D: 26.260978] [Loss_G: 1.051837] [M_global: 1.154484]\n",
      "EPOCH #  14 --------------------------------------------------\n",
      "Steps (10 / 100): [loss_D: 26.869622] [Loss_G: 1.231302] [M_global: 1.331506]\n",
      "Steps (20 / 100): [loss_D: 25.370684] [Loss_G: 1.420347] [M_global: 1.498916]\n",
      "Steps (30 / 100): [loss_D: 22.475013] [Loss_G: 1.813467] [M_global: 1.872878]\n",
      "Steps (40 / 100): [loss_D: 21.467921] [Loss_G: 2.009213] [M_global: 2.058734]\n",
      "Steps (50 / 100): [loss_D: 24.270180] [Loss_G: 2.020735] [M_global: 2.079412]\n",
      "Steps (60 / 100): [loss_D: 22.831970] [Loss_G: 2.353359] [M_global: 2.404240]\n",
      "Steps (70 / 100): [loss_D: 20.720664] [Loss_G: 2.281902] [M_global: 2.320165]\n",
      "Steps (80 / 100): [loss_D: 19.321255] [Loss_G: 2.596131] [M_global: 2.624376]\n",
      "Steps (90 / 100): [loss_D: 20.063996] [Loss_G: 2.616832] [M_global: 2.634234]\n",
      "Steps (100 / 100): [loss_D: 15.143898] [Loss_G: 3.294374] [M_global: 3.268615]\n",
      "EPOCH #  15 --------------------------------------------------\n",
      "Steps (10 / 100): [loss_D: 9.827368] [Loss_G: 4.137344] [M_global: 4.064386]\n",
      "Steps (20 / 100): [loss_D: 5.180618] [Loss_G: 5.692533] [M_global: 5.557332]\n",
      "Steps (30 / 100): [loss_D: -0.542417] [Loss_G: 7.516304] [M_global: 7.302005]\n",
      "Steps (40 / 100): [loss_D: -9.186161] [Loss_G: 8.848925] [M_global: 8.558955]\n",
      "Steps (50 / 100): [loss_D: -0.138387] [Loss_G: 8.554450] [M_global: 8.306075]\n",
      "Steps (60 / 100): [loss_D: 21.076149] [Loss_G: 6.710991] [M_global: 6.631966]\n",
      "Steps (70 / 100): [loss_D: 20.231354] [Loss_G: 5.574229] [M_global: 5.528320]\n",
      "Steps (80 / 100): [loss_D: 6.375176] [Loss_G: 7.179991] [M_global: 7.003586]\n",
      "Steps (90 / 100): [loss_D: -18.316427] [Loss_G: 10.506455] [M_global: 10.097774]\n",
      "Steps (100 / 100): [loss_D: -15.905097] [Loss_G: 10.960494] [M_global: 10.562654]\n",
      "EPOCH #  16 --------------------------------------------------\n",
      "Steps (10 / 100): [loss_D: -23.405889] [Loss_G: 11.414184] [M_global: 10.941198]\n",
      "Steps (20 / 100): [loss_D: -15.770391] [Loss_G: 10.766221] [M_global: 10.367731]\n",
      "Steps (30 / 100): [loss_D: -17.667732] [Loss_G: 10.212138] [M_global: 9.831119]\n",
      "Steps (40 / 100): [loss_D: -0.578398] [Loss_G: 9.089837] [M_global: 8.819946]\n",
      "Steps (50 / 100): [loss_D: 4.228505] [Loss_G: 8.236419] [M_global: 8.034467]\n",
      "Steps (60 / 100): [loss_D: 16.632357] [Loss_G: 5.997365] [M_global: 5.894938]\n",
      "Steps (70 / 100): [loss_D: 25.756654] [Loss_G: 4.543191] [M_global: 4.540537]\n",
      "Steps (80 / 100): [loss_D: 32.178193] [Loss_G: 4.517308] [M_global: 4.558919]\n",
      "Steps (90 / 100): [loss_D: 22.549549] [Loss_G: 4.521718] [M_global: 4.511370]\n",
      "Steps (100 / 100): [loss_D: 22.582296] [Loss_G: 4.691548] [M_global: 4.678502]\n",
      "EPOCH #  17 --------------------------------------------------\n",
      "Steps (10 / 100): [loss_D: 26.172310] [Loss_G: 4.510261] [M_global: 4.518388]\n",
      "Steps (20 / 100): [loss_D: 21.592721] [Loss_G: 4.487018] [M_global: 4.461068]\n",
      "Steps (30 / 100): [loss_D: 25.174573] [Loss_G: 4.183353] [M_global: 4.189910]\n",
      "Steps (40 / 100): [loss_D: 20.422894] [Loss_G: 4.567128] [M_global: 4.538080]\n",
      "Steps (50 / 100): [loss_D: 23.239359] [Loss_G: 4.428390] [M_global: 4.420534]\n",
      "Steps (60 / 100): [loss_D: 23.260596] [Loss_G: 3.861218] [M_global: 3.867848]\n",
      "Steps (70 / 100): [loss_D: 16.911173] [Loss_G: 3.887195] [M_global: 3.872913]\n",
      "Steps (80 / 100): [loss_D: 24.241486] [Loss_G: 3.581260] [M_global: 3.602008]\n",
      "Steps (90 / 100): [loss_D: 24.325043] [Loss_G: 3.687446] [M_global: 3.704744]\n",
      "Steps (100 / 100): [loss_D: 17.493214] [Loss_G: 4.174279] [M_global: 4.155350]\n",
      "EPOCH #  18 --------------------------------------------------\n",
      "Steps (10 / 100): [loss_D: 16.871339] [Loss_G: 4.815124] [M_global: 4.771761]\n",
      "Steps (20 / 100): [loss_D: 9.872410] [Loss_G: 5.296775] [M_global: 5.187909]\n",
      "Steps (30 / 100): [loss_D: 7.948086] [Loss_G: 5.789230] [M_global: 5.667456]\n",
      "Steps (40 / 100): [loss_D: -1.625335] [Loss_G: 6.835403] [M_global: 6.622156]\n",
      "Steps (50 / 100): [loss_D: -1.376143] [Loss_G: 7.696152] [M_global: 7.473971]\n",
      "Steps (60 / 100): [loss_D: -5.198380] [Loss_G: 9.013674] [M_global: 8.760290]\n",
      "Steps (70 / 100): [loss_D: -1.245522] [Loss_G: 7.929970] [M_global: 7.696450]\n",
      "Steps (80 / 100): [loss_D: 2.848476] [Loss_G: 7.689719] [M_global: 7.496376]\n",
      "Steps (90 / 100): [loss_D: 11.144152] [Loss_G: 7.065903] [M_global: 6.941063]\n",
      "Steps (100 / 100): [loss_D: 15.964177] [Loss_G: 5.896125] [M_global: 5.818257]\n",
      "EPOCH #  19 --------------------------------------------------\n",
      "Steps (10 / 100): [loss_D: 14.964968] [Loss_G: 6.157822] [M_global: 6.072082]\n",
      "Steps (20 / 100): [loss_D: 4.754871] [Loss_G: 7.164979] [M_global: 6.975181]\n",
      "Steps (30 / 100): [loss_D: -1.981246] [Loss_G: 7.965483] [M_global: 7.715997]\n",
      "Steps (40 / 100): [loss_D: -5.052596] [Loss_G: 9.600183] [M_global: 9.295570]\n",
      "Steps (50 / 100): [loss_D: -12.937003] [Loss_G: 10.410852] [M_global: 10.025607]\n",
      "Steps (60 / 100): [loss_D: -24.059978] [Loss_G: 13.190398] [M_global: 12.708547]\n",
      "Steps (70 / 100): [loss_D: -25.002950] [Loss_G: 15.513493] [M_global: 15.004734]\n",
      "Steps (80 / 100): [loss_D: -24.780625] [Loss_G: 14.858476] [M_global: 14.328014]\n",
      "Steps (90 / 100): [loss_D: -29.188356] [Loss_G: 14.324569] [M_global: 13.794445]\n",
      "Steps (100 / 100): [loss_D: -24.733549] [Loss_G: 13.713088] [M_global: 13.214135]\n",
      "EPOCH #  20 --------------------------------------------------\n",
      "Steps (10 / 100): [loss_D: -10.341525] [Loss_G: 12.585917] [M_global: 12.199375]\n",
      "Steps (20 / 100): [loss_D: -3.326088] [Loss_G: 11.233190] [M_global: 10.936512]\n",
      "Steps (30 / 100): [loss_D: 20.852566] [Loss_G: 7.410180] [M_global: 7.314507]\n",
      "Steps (40 / 100): [loss_D: 30.622616] [Loss_G: 4.393467] [M_global: 4.416713]\n",
      "Steps (50 / 100): [loss_D: 29.780138] [Loss_G: 3.984214] [M_global: 4.020640]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps (60 / 100): [loss_D: 28.448325] [Loss_G: 4.266831] [M_global: 4.289491]\n",
      "Steps (70 / 100): [loss_D: 17.527455] [Loss_G: 4.801738] [M_global: 4.757676]\n",
      "Steps (80 / 100): [loss_D: 16.920543] [Loss_G: 5.242315] [M_global: 5.196826]\n",
      "Steps (90 / 100): [loss_D: 15.595847] [Loss_G: 4.730126] [M_global: 4.674268]\n",
      "Steps (100 / 100): [loss_D: 18.740515] [Loss_G: 4.700145] [M_global: 4.672210]\n"
     ]
    }
   ],
   "source": [
    "D = discriminator(encoder(), decoder())\n",
    "G = generator(decoder())\n",
    "trainer = BEGAN(g_model=G, d_model=D)\n",
    "\n",
    "EPOCHS = 20\n",
    "X_train = x_train_fraud.to_numpy()\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH # ', epoch + 1, '-' * 50)\n",
    "    trainer.train(X_train, batch_size=64, steps_per_epoch=100)\n",
    "#     if (epoch+1) % 1 == 0:\n",
    "#         trainer.generator.save('gan_pre_generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 1000 more fraud\n",
    "gen_1000, x_train_gen_1000, y_train_gen_1000 = gen_data(trainer.generator, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>46.818562</td>\n",
       "      <td>2.122376</td>\n",
       "      <td>4.966058</td>\n",
       "      <td>-5.213339</td>\n",
       "      <td>0.230031</td>\n",
       "      <td>1.549477</td>\n",
       "      <td>-1.205598</td>\n",
       "      <td>-4.679256</td>\n",
       "      <td>3.683882</td>\n",
       "      <td>-3.399981</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.736072</td>\n",
       "      <td>2.648195</td>\n",
       "      <td>-2.084086</td>\n",
       "      <td>1.267950</td>\n",
       "      <td>-1.667399</td>\n",
       "      <td>-0.008234</td>\n",
       "      <td>2.165588</td>\n",
       "      <td>1.044918</td>\n",
       "      <td>2.460699</td>\n",
       "      <td>2.584993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.844614</td>\n",
       "      <td>0.793716</td>\n",
       "      <td>1.795726</td>\n",
       "      <td>2.013069</td>\n",
       "      <td>0.336180</td>\n",
       "      <td>0.617610</td>\n",
       "      <td>0.648573</td>\n",
       "      <td>1.684656</td>\n",
       "      <td>1.354170</td>\n",
       "      <td>1.261832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395104</td>\n",
       "      <td>1.120094</td>\n",
       "      <td>0.799279</td>\n",
       "      <td>0.530096</td>\n",
       "      <td>0.718772</td>\n",
       "      <td>0.245835</td>\n",
       "      <td>0.811548</td>\n",
       "      <td>0.519788</td>\n",
       "      <td>0.889305</td>\n",
       "      <td>0.987165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.206626</td>\n",
       "      <td>-0.135594</td>\n",
       "      <td>0.725467</td>\n",
       "      <td>-12.805466</td>\n",
       "      <td>-0.718602</td>\n",
       "      <td>0.044913</td>\n",
       "      <td>-3.373381</td>\n",
       "      <td>-11.403675</td>\n",
       "      <td>0.733083</td>\n",
       "      <td>-8.746175</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.284837</td>\n",
       "      <td>0.232635</td>\n",
       "      <td>-5.270448</td>\n",
       "      <td>0.035107</td>\n",
       "      <td>-5.004840</td>\n",
       "      <td>-0.888700</td>\n",
       "      <td>0.282974</td>\n",
       "      <td>-0.119818</td>\n",
       "      <td>0.419965</td>\n",
       "      <td>0.394607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>34.534291</td>\n",
       "      <td>1.576544</td>\n",
       "      <td>3.665828</td>\n",
       "      <td>-6.441269</td>\n",
       "      <td>-0.012195</td>\n",
       "      <td>1.106354</td>\n",
       "      <td>-1.633956</td>\n",
       "      <td>-5.735670</td>\n",
       "      <td>2.701262</td>\n",
       "      <td>-4.203778</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.001285</td>\n",
       "      <td>1.838617</td>\n",
       "      <td>-2.595543</td>\n",
       "      <td>0.893740</td>\n",
       "      <td>-2.132948</td>\n",
       "      <td>-0.173711</td>\n",
       "      <td>1.578925</td>\n",
       "      <td>0.656086</td>\n",
       "      <td>1.817258</td>\n",
       "      <td>1.856227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>45.042454</td>\n",
       "      <td>2.030622</td>\n",
       "      <td>4.769767</td>\n",
       "      <td>-5.067262</td>\n",
       "      <td>0.197246</td>\n",
       "      <td>1.495785</td>\n",
       "      <td>-1.151297</td>\n",
       "      <td>-4.515211</td>\n",
       "      <td>3.543905</td>\n",
       "      <td>-3.291607</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.700095</td>\n",
       "      <td>2.557671</td>\n",
       "      <td>-1.995108</td>\n",
       "      <td>1.234791</td>\n",
       "      <td>-1.596146</td>\n",
       "      <td>-0.014987</td>\n",
       "      <td>2.081345</td>\n",
       "      <td>0.986331</td>\n",
       "      <td>2.392403</td>\n",
       "      <td>2.478579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>57.417752</td>\n",
       "      <td>2.600114</td>\n",
       "      <td>6.078724</td>\n",
       "      <td>-3.812953</td>\n",
       "      <td>0.432756</td>\n",
       "      <td>1.922821</td>\n",
       "      <td>-0.726993</td>\n",
       "      <td>-3.417418</td>\n",
       "      <td>4.557916</td>\n",
       "      <td>-2.506143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.463523</td>\n",
       "      <td>3.320289</td>\n",
       "      <td>-1.484709</td>\n",
       "      <td>1.602264</td>\n",
       "      <td>-1.136390</td>\n",
       "      <td>0.154408</td>\n",
       "      <td>2.635030</td>\n",
       "      <td>1.380292</td>\n",
       "      <td>2.989487</td>\n",
       "      <td>3.195832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>114.041725</td>\n",
       "      <td>5.255000</td>\n",
       "      <td>13.005849</td>\n",
       "      <td>-0.357272</td>\n",
       "      <td>1.477548</td>\n",
       "      <td>4.227959</td>\n",
       "      <td>0.213480</td>\n",
       "      <td>-0.566312</td>\n",
       "      <td>9.033512</td>\n",
       "      <td>-0.541003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253075</td>\n",
       "      <td>7.158760</td>\n",
       "      <td>-0.139466</td>\n",
       "      <td>3.526330</td>\n",
       "      <td>-0.025261</td>\n",
       "      <td>0.899345</td>\n",
       "      <td>5.603903</td>\n",
       "      <td>3.110516</td>\n",
       "      <td>6.069761</td>\n",
       "      <td>6.512512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Time           V1           V2           V3           V4  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean     46.818562     2.122376     4.966058    -5.213339     0.230031   \n",
       "std      16.844614     0.793716     1.795726     2.013069     0.336180   \n",
       "min       6.206626    -0.135594     0.725467   -12.805466    -0.718602   \n",
       "25%      34.534291     1.576544     3.665828    -6.441269    -0.012195   \n",
       "50%      45.042454     2.030622     4.769767    -5.067262     0.197246   \n",
       "75%      57.417752     2.600114     6.078724    -3.812953     0.432756   \n",
       "max     114.041725     5.255000    13.005849    -0.357272     1.477548   \n",
       "\n",
       "                V5           V6           V7           V8           V9  ...  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  ...   \n",
       "mean      1.549477    -1.205598    -4.679256     3.683882    -3.399981  ...   \n",
       "std       0.617610     0.648573     1.684656     1.354170     1.261832  ...   \n",
       "min       0.044913    -3.373381   -11.403675     0.733083    -8.746175  ...   \n",
       "25%       1.106354    -1.633956    -5.735670     2.701262    -4.203778  ...   \n",
       "50%       1.495785    -1.151297    -4.515211     3.543905    -3.291607  ...   \n",
       "75%       1.922821    -0.726993    -3.417418     4.557916    -2.506143  ...   \n",
       "max       4.227959     0.213480    -0.566312     9.033512    -0.541003  ...   \n",
       "\n",
       "               V20          V21          V22          V23          V24  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean     -0.736072     2.648195    -2.084086     1.267950    -1.667399   \n",
       "std       0.395104     1.120094     0.799279     0.530096     0.718772   \n",
       "min      -2.284837     0.232635    -5.270448     0.035107    -5.004840   \n",
       "25%      -1.001285     1.838617    -2.595543     0.893740    -2.132948   \n",
       "50%      -0.700095     2.557671    -1.995108     1.234791    -1.596146   \n",
       "75%      -0.463523     3.320289    -1.484709     1.602264    -1.136390   \n",
       "max       0.253075     7.158760    -0.139466     3.526330    -0.025261   \n",
       "\n",
       "               V25          V26          V27          V28       Amount  \n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  \n",
       "mean     -0.008234     2.165588     1.044918     2.460699     2.584993  \n",
       "std       0.245835     0.811548     0.519788     0.889305     0.987165  \n",
       "min      -0.888700     0.282974    -0.119818     0.419965     0.394607  \n",
       "25%      -0.173711     1.578925     0.656086     1.817258     1.856227  \n",
       "50%      -0.014987     2.081345     0.986331     2.392403     2.478579  \n",
       "75%       0.154408     2.635030     1.380292     2.989487     3.195832  \n",
       "max       0.899345     5.603903     3.110516     6.069761     6.512512  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gen_1000 = pd.DataFrame(data=gen_1000, index=None, columns=x_train.columns)\n",
    "df_gen_1000.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "df['Time'] = (df['Time'].values / 3600)\n",
    "df['Amount'] = np.log10(df['Amount'].values + 1)\n",
    "\n",
    "feature = df.loc[:, df.columns != 'Class']\n",
    "true = df.loc[df['Class'] == 0]\n",
    "fraud = df.loc[df['Class'] == 1]\n",
    "true = true.loc[:, df.columns != 'Class']\n",
    "fraud = fraud.loc[:, df.columns != 'Class']\n",
    "\n",
    "boxplot_compare(fraud, df_gen_1000, 'Original Data Distribution versus BEGAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler()\n",
    "x, y = ros.fit_sample(x_train_gen_1000, y_train_gen_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBC_model_predit(x, y):   \n",
    "    x, y = ros.fit_sample(x, y)\n",
    "    clf_xgb_os = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1, eval_metric='auc',\n",
    "              gamma=0.2, gpu_id=0, importance_type='gain',\n",
    "              interaction_constraints='', learning_rate=0.02, max_delta_step=0,\n",
    "              max_depth=10, min_child_weight=2,\n",
    "              monotone_constraints='(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0)',\n",
    "              n_estimators=800, n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.7,\n",
    "              tree_method='gpu_hist', validate_parameters=1)\n",
    "    \n",
    "    clf_xgb_os.fit(x, y)  \n",
    "    y_pred_gen_os = clf_xgb_os.predict(x_test.to_numpy())\n",
    "    return y_pred_gen_os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_performance(y_test, y_pred):\n",
    "    print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "    print('Precision: ', precision_score(y_test, y_pred))\n",
    "    print('Recall: ', recall_score(y_test, y_pred))\n",
    "    print('F1 score: ', f1_score(y_test, y_pred))\n",
    "    print('ROC AUC score: ',  roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "import scikitplot as skplt\n",
    "def plot_cm(y_test, y_pred, title):\n",
    "    skplt.metrics.plot_confusion_matrix(y_test, y_pred,figsize=(8,8))\n",
    "    plt.title('Confusion Matrix ' + title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9996137776061234\n",
      "Precision:  0.9222222222222223\n",
      "Recall:  0.8469387755102041\n",
      "F1 score:  0.8829787234042554\n",
      "ROC AUC score:  0.9234078373893171\n"
     ]
    }
   ],
   "source": [
    "y_pred_gen_1000 = XGBC_model_predit(x_train_gen_1000, y_train_gen_1000)\n",
    "check_performance(y_test, y_pred_gen_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cm(y_test, y_pred_gen_1000, 'Adding GAN 1000 Fraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
